{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science for Business - Recurrent Neural Network (RNN) on Wine Reviews with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize notebook\n",
    "Load required packages and set up workspace, e.g., initialize the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mMrhkr83sqpt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDzj8w5e7DaY"
   },
   "source": [
    "Check if we are running on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FhHhJiZD6yQG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 130.000+ wine reviews (Source: https://www.kaggle.com/datasets/zynicide/wine-reviews) written by professional sommeliers. Besides a text, it contains information about the wine, such as the country of origin, the variety, the winery, the price, and the number of points given by the reviewer. The goal is this notebook is to predict the number of points given by the reviewer based on the text of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"https://raw.githubusercontent.com/olivermueller/ds4b-2024/refs/heads/main/Session_10/winemag-data-130k-v2.csv\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CureExnsIS-p"
   },
   "source": [
    "Split data into three sets: training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BBpPCg5zILlu"
   },
   "outputs": [],
   "source": [
    "training = corpus.iloc[0:80000,].sample(n=10000) # to speed up training\n",
    "validation = corpus.iloc[80000:100000,]\n",
    "test = corpus.iloc[100000:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5Mygm5yIYnh"
   },
   "source": [
    "For each dataset, store features and targets in separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "18PF5d6ZIN-U"
   },
   "outputs": [],
   "source": [
    "train_corpus_features = training[[\"description\"]]\n",
    "train_corpus_target = training[[\"points\"]]\n",
    "val_corpus_features = validation[[\"description\"]]\n",
    "val_corpus_target = validation[[\"points\"]]\n",
    "test_corpus_features = test[[\"description\"]]\n",
    "test_corpus_target = test[[\"points\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvhh11WuIeyk"
   },
   "source": [
    "Next, we have to create [TensorFlow `Datasets`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) from the Pandas dataframes. The use of TensorFlow Datasets follows a common pattern:\n",
    "\n",
    "1.   Create a dataset from raw data (e.g., a Pandas dataframe, a CSV file, multiple text files).\n",
    "2.   Apply transformations to preprocess the data in the dataset (e.g., tokenize and vectorize the texts).\n",
    "3. Iterate over the dataset and process its elements. Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "Here, we use the `from_tensor_slices` constructor to create datasets from dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QOOszgPrQVVw"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((tf.cast(train_corpus_features.values, tf.string),\n",
    "                                               tf.cast(train_corpus_target.values, tf.int32)))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((tf.cast(val_corpus_features.values, tf.string),\n",
    "                                             tf.cast(val_corpus_target.values, tf.int32)))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((tf.cast(test_corpus_features.values, tf.string),\n",
    "                                              tf.cast(test_corpus_target.values, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXbjrq6NJ1Qk"
   },
   "source": [
    "Display some stats and examples from the created datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j9LXPIY-XxDH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (1,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (1,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "===\n",
      "inputs[0]: tf.Tensor(b\"This Cab-based Bordeaux blend is very dense in fruit and also very Tannic with a capital T. Such is the astringency that it may never go away before the blackberry and black currant fruit drops out. Nonetheless it's dry and savory and, in its own Rockpiley way, classic. Drink with superrich barbecue, well-marbled grilled beef and such. Tasted twice.\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(89, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"===\")\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uwh4TWJbVFY9"
   },
   "source": [
    "# Vectorize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM7gEBL8KHzg"
   },
   "source": [
    "We will now use [TensorFlow's `TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) function to transform raw texts into numerical vectors. To do this, we simply map words to integers (`output_mode = 'int'`). To get document representation of a fixed length, we limit the length of documents to 100 tokens (longer documents will be truncated, shorter documents will be padded with zeros). We also set a maximum vocabulary size of 10000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oyJW-JetIN2w"
   },
   "outputs": [],
   "source": [
    "max_tokens = 10000\n",
    "max_length = 100\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens = max_tokens,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4ElfvWtKj0Q"
   },
   "source": [
    "Some apects of the `TextVectorization` function (e.g., the size and contents of the vocabulary) have to be fit using training data, which can be done with the `adapt` function (which can only be applied to the features (x) of the dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s6xCAUAOMdYH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 21:15:53.393304: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_ds_features_only = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(train_ds_features_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkQu4KlNLftU"
   },
   "source": [
    "Show the vocabulary that our vectorizer knows after being fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dn0lt-7CRaCq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'and', 'the', 'a', 'of', 'with', 'this', 'is', 'wine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjeZpApaLvyx"
   },
   "source": [
    "Now, we can apply our adapted `text_vectorization` function to all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jHGn2peqMYuP"
   },
   "outputs": [],
   "source": [
    "vectorized_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "vectorized_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "vectorized_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_WzVu2WMEn-"
   },
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0etTA2eAUB6G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (1, 100)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (1,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "===\n",
      "inputs[0]: tf.Tensor(\n",
      "[   7 7069  598   52    8   63  144   11   16    2  114   63  104    6\n",
      "    4 7052 8254  738    8    3  953   20   13  619 1067  557  853  406\n",
      "    3   53    2   29  137   16 3846   82 1514   14   43    2  141    2\n",
      "   11   14  643 9072  301  452   25    6 3294  952 7575  367  500    2\n",
      "  738 1385 3276    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(100,), dtype=int64)\n",
      "targets[0]: tf.Tensor(89, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in vectorized_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"===\")\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `get_vocabulary()` to get the word behind a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tasted'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[1385]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9QH9PcrSa7J"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_K1l5L-MQ7z"
   },
   "source": [
    "We are now ready to specify a neural network and feed it with the vectroized datasets. For convenience, we define a custome function `get_model` which defines the network architecture, creates a model from it, and compiles this model (by defining, e.g., an otpimizer and loss function).\n",
    "\n",
    "Instead of averaging or flattening the outputs of the embedding layer, a RNN/LSTM layer can directly process its 2D output (i.e., it takes a sequence of vectors as input instead of a single vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZMB14gBYSblz"
   },
   "outputs": [],
   "source": [
    "def get_model(hidden_dim=32):\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "    embedded = layers.Embedding(input_dim=max_tokens, output_dim=300, mask_zero=True)(inputs)\n",
    "    hidden1 = layers.LSTM(hidden_dim, return_sequences = False)(embedded)\n",
    "    outputs = layers.Dense(1, activation = \"linear\")(hidden1)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer = tf.optimizers.Adam(),\n",
    "                  loss = \"mean_absolute_error\",\n",
    "                  metrics = [\"mean_absolute_error\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWZtLzduT_sH"
   },
   "source": [
    "Instantiate model and show it's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "02bcqmcvTIDW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">42,624</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │  \u001b[38;5;34m3,000,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m42,624\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,042,657</span> (11.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,042,657\u001b[0m (11.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,042,657</span> (11.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,042,657\u001b[0m (11.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W4SzaRqUExq"
   },
   "source": [
    "Fit model on training data and save best model to disk. We use the validation set to monitor how the performance of the model evolves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQZ8zbxbSzZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m 3721/10000\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 31ms/step - loss: 51.1082 - mean_absolute_error: 51.1082"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"lstm.keras\", save_best_only=True)]\n",
    "\n",
    "history = model.fit(vectorized_train_ds.cache(),\n",
    "          validation_data = vectorized_val_ds.cache(),\n",
    "          epochs = 3,\n",
    "          batch_size = 128,\n",
    "          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7NOcSDY0Y6I"
   },
   "source": [
    "Plot the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoHl0JaJ5fJm"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ347rt_Tx0G"
   },
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKR36ArkT2Gq"
   },
   "source": [
    "Load best model from training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zA_ON4yBTb2a"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"mlp.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LRhBvwPT1q-"
   },
   "source": [
    "Make predictions on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yckI-BTWSTFm"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(vectorized_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMFi18uLT7tG"
   },
   "source": [
    "Calculate prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afIwDkWYS_i4"
   },
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(test_corpus_target, preds))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1kHkaqxz9sVdaOC2i4FJVOOFW9cCiBkYu",
     "timestamp": 1636383829898
    }
   ]
  },
  "kernelspec": {
   "display_name": "prodok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
